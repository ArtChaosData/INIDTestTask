# INIDTestTask
 Тестовое задание (№2б работа с отчётами РГМ) на позицию data-инженера (jun) в ИНИД ЦПУР
 
_В ноутбуках есть обширные объяснения в markdown-формате!_

| Subject | What is it | Comment |
| --- | --- | --- |
| `Data` | папка с отчётами РГМ |
| `Data/Doc` | отчёты в doc-формате | 
| `Data/ЗОС, х.20хх.docx\pdf` | отчёты, с которыми можно работать|
| `GetTheData.ipynb`| ноутбук для скрейпинга данных с сайта РГМ| 
| `ScriptToHalfManualDataMine.ipynb`| ноутбук для полуручного скрейпинга отчётов| Присутствует ошибка
| `navec_news_v1_1B_250K_300d_100q.tar`| модель для NAVEC| Для вычленения абзацев с тегом «LOC»
| `slovnet_ner_news_v1.tar`| модель для SLOVNET| Для вычленения абзацев с тегом «LOC»
| `ntd-861-20210304-191207-1-497.pdf`| ПОСТАНОВЛЕНИЕ ОБ УТВЕРЖДЕНИИ САНИТАРНЫХ ПРАВИЛ И НОРМ САНПИН 1.2.3685-21 "ГИГИЕНИЧЕСКИЕ НОРМАТИВЫ И ТРЕБОВАНИЯ К ОБЕСПЕЧЕНИЮ БЕЗОПАСНОСТИ И (ИЛИ) БЕЗВРЕДНОСТИ ДЛЯ ЧЕЛОВЕКА ФАКТОРОВ СРЕДЫ ОБИТАНИЯ" (с.  1-497)| Для возможной обработки и дальнейшим re.search() по абзацам для вычленения названия химических элементов

Что касается парсера `ScriptToHalfManualDataMine.ipynb` — если исправить ошибку¹, то это лучшее решение, так как это позволит увеличить скорость ручного парсинга, тогда как полностью автоматический парсинг я считаю в данном случае вариантом не совсем рабочим, потому что та же пара NAVEC+SLOVNET не выделяла на тестах г. Бугульма как 'LOC', и, подозреваю, что это был бы не единичный случай. В моём случае скрейпер отлавливает отдельно аварийное загрязнение (важно, потому что ПДК м.р. и ПДК с.с — разные меры), позволит точнее определить локацию (кроме того, его можно апгрейдить для геокодирования с помощью API, но с учётом возникших проблем нее стал это добавлять), 

¹ — ошибка парсера:
```
IOPub data rate exceeded.
The notebook server will temporarily stop sending output
to the client in order to avoid crashing it.
To change this limit, set the config variable
`--NotebookApp.iopub_data_rate_limit`.
```

Что касается отчёта `ntd-861-20210304-191207-1-497.pdf` — я предполагаю, что возможно полностью автоматизировать процесс, если искать данные о загрязнениях, с помощью готового списка веществ, которые отслеживает РГМ, однако, существует опасность того, что РГМ пишет название вещества не так, как он указан в постановлении. 

Что касается проблем, которые возникли при работе с данными:
- NAVEC+SLOVNET не отлавливают названий химических веществ
- NAVEC+SLOVNET отлавливают не все нужные локации (вероятно, исправляется наверняка существующими регистрами населённых пунктов.
- в случае геокодирования, сложно определить точную координату розлива веществ, даже с учётом ручного парсинга места розлива.
- РГМ в разных отчётах выдаёт информацию о водных объектах или в тексте, или в табличном виде, при этом специалисты РГМ делят эти данные по разным признакам: класс опасности вещества или бассеины рек. Последнее, с учётом указание области особенно смешно, потому что heatmap по таким данным даст чёткую картинку по границам регионов. Это большая проблема.
